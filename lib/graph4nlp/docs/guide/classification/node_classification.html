<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Node Classification &mdash; Graph4NLP v0.4.1 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Graph Classification" href="graph_classification.html" />
    <link rel="prev" title="Chapter 6. Classification" href="../classification.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Graph4NLP
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../welcome/installation.html">Install Graph4NLP</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../graphdata.html">Chapter 1. Graph Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset.html">Chapter 2. Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../construction.html">Chapter 3. Graph Construction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gnn.html">Chapter 4. Graph Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../decoding.html">Chapter 5. Decoder</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../classification.html">Chapter 6. Classification</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Node Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#bilstmfeedforwardnnlayer">BiLSTMFeedForwardNNLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bilstmfeedforwardnn">BiLSTMFeedForwardNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#feedforwardnn">FeedForwardNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="graph_classification.html">Graph Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="link_prediction.html">Link Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="kgcompletion.html">Knowledge Graph Completion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation.html">Chapter 7. Evaluations and Loss components</a></li>
</ul>
<p class="caption"><span class="caption-text">Module API references</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules/data.html">graph4nlp.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/datasets.html">graph4nlp.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/graph_construction.html">graph4nlp.graph_construction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/graph_embedding.html">graph4nlp.graph_embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/prediction.html">graph4nlp.prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/loss.html">graph4nlp.loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/evaluation.html">graph4nlp.evaluation</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/text_classification.html">Text Classification Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/semantic_parsing.html">Semantic Parsing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/math_word_problem.html">Math Word Problem Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/knowledge_graph_completion.html">Knowledge Graph Completion Tutorial</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Graph4NLP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../classification.html">Chapter 6. Classification</a> &raquo;</li>
      <li>Node Classification</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/guide/classification/node_classification.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="node-classification">
<span id="guide-node-classification"></span><h1>Node Classification<a class="headerlink" href="#node-classification" title="Permalink to this headline">¶</a></h1>
<p>Node classification is a downstream task that are normally observed in the GNN-based NLP tasks, such as sequence labeling and name entity recognition. The process is about classify the label of the each node in the graph based on the node embeddings that learnt from the GNNs modules.</p>
<p>To facilitate the implementation of node classification task, we provide both high-level and low-level APIs to users to easily define a multi-layer node classification function. Besides, for each level’s APIs, we support two popularly used node classifiers, one is based on the BiLSTM and feedforward neural network (BiLSTMFeedForwardNN), another one is based on simple feedforward neural network (FeedForwardNN).</p>
<div class="section" id="bilstmfeedforwardnnlayer">
<h2>BiLSTMFeedForwardNNLayer<a class="headerlink" href="#bilstmfeedforwardnnlayer" title="Permalink to this headline">¶</a></h2>
<p>This function is based on a combination of the BiLSTM layer and a feedforward layer. The low-level function defines the a single layer classifier with the input of node embedding tensor and the output of legit tensor after classification.</p>
<p>Below is an example to construct the BiLSTMFeedForwardNNlayer module. If <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, we add an additional hidden layer after the last. Else, we directly use the output of the lstm as the classification logits.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="k">class</span> <span class="nc">BiLSTMFeedForwardNNLayer</span><span class="p">(</span><span class="n">NodeClassifierLayerBase</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
     <span class="nb">super</span><span class="p">(</span><span class="n">BiLSTMFeedForwardNNLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="o">=</span><span class="n">output_size</span>

     <span class="k">if</span> <span class="n">hidden_size</span><span class="o">!=</span><span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">)</span>
     <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</pre></div>
</div>
<p>After the construction of the module, the next step is to make the <code class="docutils literal notranslate"><span class="pre">forward()</span></code> part. The user can specify the index of nodes that needs to be classified in <code class="docutils literal notranslate"><span class="pre">node_idx</span></code>. If not specified, the classifier will be applied to all the nodes.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_emb</span><span class="p">,</span> <span class="n">node_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

   <span class="k">if</span> <span class="n">node_idx</span><span class="p">:</span>
       <span class="n">node_emb</span> <span class="o">=</span> <span class="n">node_emb</span><span class="p">[</span><span class="n">th</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node_idx</span><span class="p">),</span> <span class="p">:]</span>

   <span class="n">batch_size</span><span class="o">=</span><span class="n">node_emb</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

   <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
   <span class="n">lstm_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">node_emb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">)</span>

   <span class="k">if</span>  <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">lstm_out</span>
   <span class="k">else</span><span class="p">:</span>
      <span class="n">lstm_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
</pre></div>
</div>
<p>The final output of this module is the classification logits.</p>
</div>
<div class="section" id="bilstmfeedforwardnn">
<h2>BiLSTMFeedForwardNN<a class="headerlink" href="#bilstmfeedforwardnn" title="Permalink to this headline">¶</a></h2>
<p>To facilitate the easily implementation of the pipeline of GNN-based NLP application, we also provide the high-level function for node classification, where the input and output are both the graph in type of <cite>GraphData</cite>.</p>
<p>Below is an example to construct the BiLSTMFeedForwardNN module.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">num_class</span></code> defines the the number of node categoriey for classification.</p>
<p>After define the module, we implement the``forward()`` part. In the <code class="docutils literal notranslate"><span class="pre">forward()</span></code> part, the node embedding tensor should be stored in the node feature field named <code class="docutils literal notranslate"><span class="pre">node_emb</span></code>  in the input_graph for classification. If the input graph is a <code class="docutils literal notranslate"><span class="pre">batched</span> <span class="pre">graphs</span></code>, we can get the node embedding and do the classification as</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node_emb_padded</span><span class="o">=</span><span class="n">input_graph</span><span class="o">.</span><span class="n">node_features</span><span class="p">[</span><span class="s1">&#39;node_emb&#39;</span><span class="p">]</span>
<span class="n">len_emb</span><span class="o">=</span><span class="n">node_emb_padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">bilstm_emb</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">node_emb_padded</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">len_emb</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>If the input graph is an origin graph, the operation is as</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">node_emb_padded</span><span class="o">=</span><span class="n">input_graph</span><span class="o">.</span><span class="n">batch_node_features</span><span class="p">[</span><span class="s1">&#39;node_emb&#39;</span><span class="p">]</span>
<span class="n">bilstm_emb</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">node_emb_padded</span><span class="p">)</span>
</pre></div>
</div>
<p>After getting the <code class="docutils literal notranslate"><span class="pre">bilstm_emb</span></code>, which is also the computed logit tensor for each nodes in the graph, they are stored in the node feature field named <code class="docutils literal notranslate"><span class="pre">node_logit</span></code> as</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_graph</span><span class="o">.</span><span class="n">batch_node_features</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">bilstm_emb</span>
</pre></div>
</div>
</div>
<div class="section" id="feedforwardnn">
<h2>FeedForwardNN<a class="headerlink" href="#feedforwardnn" title="Permalink to this headline">¶</a></h2>
<p>This function is based on a combination of several feedforward layer. The low-level function defines the classifier layers with the input of node embedding tensor and the output of legit tensor after classification.</p>
<p>Below is an example to construct the FeedForwardNNLayer module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForwardNNLayer</span><span class="p">(</span><span class="n">NodeClassifierLayerBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()):</span>
          <span class="nb">super</span><span class="p">(</span><span class="n">FeedForwardNNLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>


          <span class="c1">#build the linear module list</span>
          <span class="n">module_seq</span><span class="o">=</span><span class="p">[]</span>

          <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)):</span>

             <span class="k">if</span> <span class="n">layer_idx</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                  <span class="n">module_seq</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;linear&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">layer_idx</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">])))</span>
             <span class="k">else</span><span class="p">:</span>
                  <span class="n">module_seq</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;linear&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">layer_idx</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">[</span><span class="n">layer_idx</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">])))</span>

             <span class="n">module_seq</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;activate&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">layer_idx</span><span class="p">),</span><span class="n">activation</span><span class="p">))</span>

          <span class="n">module_seq</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;linear_end&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">num_class</span><span class="p">)))</span>

          <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">(</span><span class="n">module_seq</span><span class="p">))</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> can be a list of int values. Each element in <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> is the size of each hidden layer.</p>
<p>After construct the module, the next step is to make the <code class="docutils literal notranslate"><span class="pre">forward()</span></code> part. The user can specify the index of nodes that needs to be classified in <code class="docutils literal notranslate"><span class="pre">node_idx</span></code>. If not specified, the classifier will be applied to all the nodes. The output of this module is the node embedding tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_emb</span><span class="p">,</span> <span class="n">node_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">node_idx</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">node_emb</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_emb_new</span> <span class="o">=</span> <span class="n">node_emb</span><span class="p">[</span><span class="n">th</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node_idx</span><span class="p">),</span> <span class="p">:]</span>  <span class="c1"># get the required node embeddings.</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">new_emb_new</span><span class="p">)</span>
</pre></div>
</div>
<p>To facilitate the easily implementation of the pipeline of GNN-based NLP application, we also provide the high-level function for multi-layer node classification, where the input and output are both the graph in type of <cite>GraphData</cite>. The node embedding tensor should be stored in the node feature field named “node_emb”  in the input_graph for classification. The computed logit tensor for each nodes in the graph are stored in the node feature field named “node_logits”. The input graph can be either batched graph or original single graph. Below is an example to define and call the FeedForwardNN API.</p>
<p>Below is an example to construct the FeedForwardNN module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForwardNN</span><span class="p">(</span><span class="n">NodeClassifierBase</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">input_size</span><span class="p">,</span>
               <span class="n">num_class</span><span class="p">,</span>
               <span class="n">hidden_size</span><span class="p">,</span>
               <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()):</span>
      <span class="nb">super</span><span class="p">(</span><span class="n">FeedForwardNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">=</span><span class="n">FeedForwardNNLayer</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
</pre></div>
</div>
<p>After the construction of the module, the next step is to make the <code class="docutils literal notranslate"><span class="pre">forward()</span></code> part. The user can specify the index of nodes that needs to be classified in <code class="docutils literal notranslate"><span class="pre">node_idx</span></code>. If not specified, the classifier will be applied to all the nodes. After getting the <code class="docutils literal notranslate"><span class="pre">node_emb</span></code>, which is also the computed logit tensor for each nodes in the graph, they are stored in the node feature field named <code class="docutils literal notranslate"><span class="pre">node_logit</span></code> and the output is the GraphData.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_graph</span><span class="p">):</span>
      <span class="n">node_emb</span><span class="o">=</span><span class="n">input_graph</span><span class="o">.</span><span class="n">node_features</span><span class="p">[</span><span class="s1">&#39;node_emb&#39;</span><span class="p">]</span>
      <span class="n">input_graph</span><span class="o">.</span><span class="n">node_features</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">node_emb</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">input_graph</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../classification.html" class="btn btn-neutral float-left" title="Chapter 6. Classification" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="graph_classification.html" class="btn btn-neutral float-right" title="Graph Classification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Graph4AI Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>